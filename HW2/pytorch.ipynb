{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"pytorch.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dTyFX3D0519n","colab_type":"text"},"source":["# Pytorch Tutorial"]},{"cell_type":"markdown","metadata":{"id":"jnyV3pED519o","colab_type":"text"},"source":["Pytorch is a popular deep learning framework and it's easy to get started."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-29T10:54:42.961693Z","start_time":"2020-03-29T10:54:42.628513Z"},"id":"vxKQ-yK3519p","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.utils.data as data\n","import torchvision\n","import torchvision.transforms as transforms\n","from tqdm import tqdm, trange\n","from torch import optim\n","from torch.autograd import Variable\n","import time\n","\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 10"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xGhkqYfM519s","colab_type":"text"},"source":["First, we read the mnist data, preprocess them and encapsulate them into dataloader form."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-29T10:54:44.064917Z","start_time":"2020-03-29T10:54:44.033754Z"},"id":"lLLUyNaW519s","colab_type":"code","colab":{}},"source":["# preprocessing\n","normalize = transforms.Normalize(mean=[.5], std=[.5])\n","transform = transforms.Compose([transforms.ToTensor(), normalize])\n","\n","# download and load the data\n","train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n","test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n","\n","# encapsulate them into dataloader form\n","train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n","test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ilQrWvQB519u","colab_type":"text"},"source":["Then, we define the model, object function and optimizer that we use to classify."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-29T11:28:47.379833Z","start_time":"2020-03-29T11:28:47.234935Z"},"id":"QVrxW_jr519v","colab_type":"code","colab":{}},"source":["class SimpleNet(nn.Module):\n","# TODO:define model\n","    def __init__(self):\n","        super(SimpleNet, self).__init__()\n","        self.layer_1 = torch.nn.Sequential(torch.nn.Conv2d(1, 128, kernel_size = 3, stride = 1, padding = 1),\n","                                        torch.nn.ReLU(),\n","                                        torch.nn.Conv2d(128, 512, kernel_size = 3, stride = 1, padding = 1),\n","                                        torch.nn.ReLU(),\n","                                        torch.nn.MaxPool2d(stride = 2, kernel_size = 2))\n","        self.layer_2 = torch.nn.Sequential(torch.nn.Linear(14 * 14  * 512, 2048),\n","                                        torch.nn.ReLU(),\n","                                        torch.nn.Dropout(p = 0.5),\n","                                        torch.nn.Linear(2048, 10))\n","    \n","    def forward(self, x):\n","        x = self.layer_1(x)\n","        x = x.view(-1, 14 * 14 * 512)\n","        x = self.layer_2(x)\n","        return x\n","    \n","model = SimpleNet()\n","model.cuda()\n","\n","# TODO:define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = 0.0002)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I5SDv4Xz519x","colab_type":"text"},"source":["Next, we can start to train and evaluate!"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-29T12:45:36.750384Z","start_time":"2020-03-29T11:28:49.001187Z"},"scrolled":true,"id":"9y5uHNT1519y","colab_type":"code","outputId":"78b18274-1358-4e9e-eeb4-a395d84fa9f3","executionInfo":{"status":"ok","timestamp":1586420827746,"user_tz":-480,"elapsed":443157,"user":{"displayName":"Ruiwen Zhou","photoUrl":"","userId":"11164342359578833411"}},"colab":{"base_uri":"https://localhost:8080/","height":689}},"source":["# train and evaluate\n","for epoch in range(NUM_EPOCHS):\n","    train_correct, train_total = 0, len(train_dataset)\n","    test_correct, test_total = 0, len(test_dataset)\n","    for images, labels in tqdm(train_loader):\n","        # TODO:forward + backward + optimize\n","        X_train, y_train = Variable(images).cuda(), Variable(labels).cuda()\n","        optimizer.zero_grad()\n","        outputs = model(X_train)\n","        _, y_pred = torch.max(outputs, 1)\n","        train_correct += torch.sum(y_pred == y_train.data)\n","        loss = criterion(outputs, y_train)\n","        loss.backward()\n","        optimizer.step()\n","        \n","    # evaluate\n","    # TODO:calculate the accuracy using traning and testing dataset\n","    for images, labels in tqdm(test_loader):\n","        X_test, y_test = Variable(images).cuda(), Variable(labels).cuda()\n","        outputs = model(X_test)\n","        _, y_pred = torch.max(outputs, 1)\n","        test_correct += torch.sum(y_pred == y_test.data)\n","    \n","    print(\"Training Accuracy: %.2f%%\" % (train_correct.cpu().numpy() / train_total * 100))\n","    print(\"Testing Accuracy: %.2f%%\" % (test_correct.cpu().numpy() / test_total * 100))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["100%|██████████| 468/468 [00:41<00:00, 11.19it/s]\n","100%|██████████| 78/78 [00:01<00:00, 39.62it/s]\n","  0%|          | 2/468 [00:00<00:28, 16.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 94.20%\n","Testing Accuracy: 97.98%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:41<00:00, 11.15it/s]\n","100%|██████████| 78/78 [00:01<00:00, 40.13it/s]\n","  0%|          | 2/468 [00:00<00:28, 16.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 98.50%\n","Testing Accuracy: 98.68%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.06it/s]\n","100%|██████████| 78/78 [00:01<00:00, 40.67it/s]\n","  0%|          | 2/468 [00:00<00:28, 16.40it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 98.86%\n","Testing Accuracy: 98.61%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.06it/s]\n","100%|██████████| 78/78 [00:01<00:00, 40.19it/s]\n","  0%|          | 2/468 [00:00<00:27, 16.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.22%\n","Testing Accuracy: 98.70%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.07it/s]\n","100%|██████████| 78/78 [00:01<00:00, 41.44it/s]\n","  0%|          | 2/468 [00:00<00:29, 16.05it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.41%\n","Testing Accuracy: 98.68%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.07it/s]\n","100%|██████████| 78/78 [00:01<00:00, 41.34it/s]\n","  0%|          | 2/468 [00:00<00:27, 16.94it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.44%\n","Testing Accuracy: 98.78%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.07it/s]\n","100%|██████████| 78/78 [00:01<00:00, 42.14it/s]\n","  0%|          | 2/468 [00:00<00:27, 16.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.53%\n","Testing Accuracy: 98.78%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.07it/s]\n","100%|██████████| 78/78 [00:01<00:00, 40.55it/s]\n","  0%|          | 2/468 [00:00<00:27, 16.69it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.57%\n","Testing Accuracy: 98.75%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.07it/s]\n","100%|██████████| 78/78 [00:01<00:00, 41.88it/s]\n","  0%|          | 2/468 [00:00<00:27, 16.95it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.64%\n","Testing Accuracy: 98.59%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 468/468 [00:42<00:00, 11.07it/s]\n","100%|██████████| 78/78 [00:01<00:00, 41.47it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.62%\n","Testing Accuracy: 98.90%\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"X6CF1nO35191","colab_type":"text"},"source":["#### Q5:\n","Please print the training and testing accuracy."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-03-29T12:48:44.342672Z","start_time":"2020-03-29T12:46:00.416091Z"},"id":"IZverhPI5191","colab_type":"code","outputId":"acf2d394-2db9-4c41-b14c-6bf515fb0b06","executionInfo":{"status":"ok","timestamp":1586420846443,"user_tz":-480,"elapsed":16363,"user":{"displayName":"Ruiwen Zhou","photoUrl":"","userId":"11164342359578833411"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["model.eval()\n","train_correct, train_total = 0, len(train_dataset)\n","test_correct, test_total = 0, len(test_dataset)\n","\n","for images, labels in tqdm(train_loader):\n","    X_train, y_train = Variable(images).cuda(), Variable(labels).cuda()\n","    outputs = model(X_train)\n","    _, y_pred = torch.max(outputs, 1)\n","    train_correct += torch.sum(y_pred == y_train.data)\n","\n","for images, labels in tqdm(test_loader):\n","    X_test, y_test = Variable(images).cuda(), Variable(labels).cuda()\n","    outputs = model(X_test)\n","    _, y_pred = torch.max(outputs, 1)\n","    test_correct += torch.sum(y_pred == y_test.data)\n","    \n","print(\"Training Accuracy: %.2f%%\" % (train_correct.cpu().numpy() / train_total * 100))\n","print(\"Testing Accuracy: %.2f%%\" % (test_correct.cpu().numpy() / test_total * 100))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["100%|██████████| 468/468 [00:10<00:00, 43.30it/s]\n","100%|██████████| 78/78 [00:01<00:00, 43.37it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Training Accuracy: 99.81%\n","Testing Accuracy: 99.06%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zEzgCj9D5194","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}